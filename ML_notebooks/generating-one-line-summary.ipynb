{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# simpleT5: Generating Title\n\n**simpleT5** is built on top of PyTorch-lightning and Transformers","metadata":{}},{"cell_type":"markdown","source":"## Dataset Prepration","metadata":{}},{"cell_type":"markdown","source":"**Load the dataset in Pandas DataFrame**","metadata":{}},{"cell_type":"code","source":"import re\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\n\ndata_file = '../input/arxiv/arxiv-metadata-oai-snapshot.json'\n\n\"\"\" Using `yield` to load the JSON file in a loop to prevent Python memory issues if JSON is loaded directly\"\"\"\n\ndef get_metadata():\n    with open(data_file, 'r') as f:\n        for line in f:\n            yield line\n\n            \n            \n# we will consider below 3 categories for training \npaper_categories = [\"cs.AI\", # Artificial Intelligence\n                    \"cs.CV\", # Computer Vision and Pattern Recognition\n                    \"cs.LG\"] # Machine Learning\n\n\n\ndef build_dataset(categories=paper_categories):\n    titles = []\n    abstracts = []\n    metadata = get_metadata()\n    for paper in tqdm(metadata):\n        paper_dict = json.loads(paper)\n        category = paper_dict.get('categories')\n        if category in categories:\n            try:\n                year = int(paper_dict.get('journal-ref')[-4:])\n                titles.append(paper_dict.get('title'))\n                abstracts.append(paper_dict.get('abstract').replace(\"\\n\",\"\"))\n            except:\n                pass \n\n    papers = pd.DataFrame({'title': titles,'abstract': abstracts})\n    papers = papers.dropna()\n    papers[\"title\"] = papers[\"title\"].apply(lambda x: re.sub('\\s+',' ', x))\n    papers[\"abstract\"] = papers[\"abstract\"].apply(lambda x: re.sub('\\s+',' ', x))\n\n    del titles, abstracts\n    return papers","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:00:15.358776Z","iopub.execute_input":"2022-03-09T10:00:15.359117Z","iopub.status.idle":"2022-03-09T10:00:15.373301Z","shell.execute_reply.started":"2022-03-09T10:00:15.359041Z","shell.execute_reply":"2022-03-09T10:00:15.372456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"papers = build_dataset()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:00:19.594079Z","iopub.execute_input":"2022-03-09T10:00:19.594399Z","iopub.status.idle":"2022-03-09T10:01:32.096968Z","shell.execute_reply.started":"2022-03-09T10:00:19.59437Z","shell.execute_reply":"2022-03-09T10:01:32.096137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"!pip install simplet5","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-09T10:01:32.09841Z","iopub.execute_input":"2022-03-09T10:01:32.098729Z","iopub.status.idle":"2022-03-09T10:01:59.006725Z","shell.execute_reply.started":"2022-03-09T10:01:32.0987Z","shell.execute_reply":"2022-03-09T10:01:59.00579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# simpleT5 expects training and validation dataframes to have 2 columns: \"source_text\" and \"target_text\"\npapers = papers[['abstract','title']]\npapers.columns = [\"source_text\", \"target_text\"]\n\n# let's add a prefix to source_text, to uniquely identify kind of task we are performing on the data, in this case --> \"summarize\"\npapers['source_text'] = \"summarize: \"+ papers['source_text']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:01:59.010159Z","iopub.execute_input":"2022-03-09T10:01:59.010465Z","iopub.status.idle":"2022-03-09T10:01:59.022372Z","shell.execute_reply.started":"2022-03-09T10:01:59.01043Z","shell.execute_reply":"2022-03-09T10:01:59.021467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split the data into training and test\nfrom sklearn.model_selection import train_test_split\n\ntrain_df, test_df = train_test_split(papers, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:01:59.024159Z","iopub.execute_input":"2022-03-09T10:01:59.024836Z","iopub.status.idle":"2022-03-09T10:01:59.960478Z","shell.execute_reply.started":"2022-03-09T10:01:59.024799Z","shell.execute_reply":"2022-03-09T10:01:59.95964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import\nfrom simplet5 import SimpleT5\n\n# instatntiate\nmodel = SimpleT5()\n\n# load\nmodel.from_pretrained(\"t5\",\"t5-base\")\n\n# train\nmodel.train(train_df=train_df, eval_df=test_df, source_max_token_len=512, target_max_token_len=128, max_epochs=5, batch_size=8, use_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:01:59.964554Z","iopub.execute_input":"2022-03-09T10:01:59.965278Z","iopub.status.idle":"2022-03-09T10:27:40.797486Z","shell.execute_reply.started":"2022-03-09T10:01:59.965234Z","shell.execute_reply":"2022-03-09T10:27:40.796597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inferencing\n**simpleT5** saves your model at every epoch in \"outputs\" folder (default)","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/working\nfrom IPython.display import FileLink\ndisplay(FileLink(\"simplet5-epoch-4-train-loss-1.1383-val-loss-1.9299\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:40:36.690039Z","iopub.execute_input":"2022-03-09T10:40:36.690381Z","iopub.status.idle":"2022-03-09T10:40:37.469097Z","shell.execute_reply.started":"2022-03-09T10:40:36.690348Z","shell.execute_reply":"2022-03-09T10:40:37.467757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls outputs/","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:28:47.879633Z","iopub.execute_input":"2022-03-09T10:28:47.879989Z","iopub.status.idle":"2022-03-09T10:28:48.759368Z","shell.execute_reply.started":"2022-03-09T10:28:47.879956Z","shell.execute_reply":"2022-03-09T10:28:48.758443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load a trained model\nmodel.load_model(\"outputs/SimpleT5-epoch-4-train-loss-1.1577\", use_gpu=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:32:02.379541Z","iopub.execute_input":"2022-03-09T10:32:02.379916Z","iopub.status.idle":"2022-03-09T10:32:02.399442Z","shell.execute_reply.started":"2022-03-09T10:32:02.379885Z","shell.execute_reply":"2022-03-09T10:32:02.398651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_abstracts = test_df.sample(10)\n\nfor i, abstract in sample_abstracts.iterrows():\n    print(f\"===== Abstract =====\")\n    print(abstract['source_text'])\n    summary= model.predict(abstract['source_text'])[0]\n    print(f\"\\n===== Actual Title =====\")\n    print(f\"{abstract['target_text']}\")\n    print(f\"\\n===== Generated Title =====\")\n    print(f\"{summary}\")\n    print(\"\\n +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T10:32:04.559982Z","iopub.execute_input":"2022-03-09T10:32:04.560315Z","iopub.status.idle":"2022-03-09T10:32:08.830975Z","shell.execute_reply.started":"2022-03-09T10:32:04.560285Z","shell.execute_reply":"2022-03-09T10:32:08.830102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}